\part{System Design and Methodology}

% \textbf{NOTE:}
% Included here is the system architecture and explanation of each process. Discuss
% how each problem was developed and \textbf{where the algorithm will be used} in
% solving the problem.

\begin{figure}[hbt!]
	\center
	\noindent\adjustbox{width=\textwidth}{\includesvg{images/salitrato_colored_flowchart}}
	\caption{SaLitrato process flowchart}
	\label{fig:salitrato_flowchart}
\end{figure}

\section*{Design Goal Overview}

\hspace\parindent
The figure (Fig \ref{fig:salitrato_flowchart}) above illustrates how the system software that
implements an in-image text search method will search for and extract text within an image or
multiple image files using Boyer-Moore algorithm. A text pattern within an image file will be
detected and located using the Boyer-Moore algorithm. The system will additionally incorporate the
use of optical character recognition (OCR) API with the version of Tesseract 4 to identify and
extract texts from images.

\hfill

The user will create and select a folder to which the pre-processed file would be stored, the
aforementioned file would then be checked if it is one of the supported formats. It will then be
subjected to the Python Tesseract package where it will undergo a connected component analysis that
gathers and stores the outlines. The outlines will then be further analyzed in a fixed pitch or if
they are proportional texts. They will then be separated into words according to character spacing
by using character cells.

\hfill

Lastly, it will undertake a two-pass procedure using an adaptive classifier to enhance the accuracy
of the recognition process. Only then will it be put through the Boyer-Moore Algorithm where the
user-inputted characters will be compared to the text from the post-processed file. To be able to
assist the users in easily identifying the result, the software also has a feature that highlights
the location of the text pattern inside an image file or displays a prompt if the pattern is not
recognized.

\section*{System Architecture}

\hspace\parindent
This software is built using a modular, object-oriented approach with focus on readability,
maintainability, and extensibility. It follows the traditional \texttt{layered architecture}, with
several layers managing the user interface, application logic, and system interactions.

\begin{figure}[hbt!]
    \center
    \noindent\adjustbox{width=\textwidth}{\includesvg{images/archpat}}
    \caption{System architecture of SaLitrato}
    \label{fig:plannedUI}
\end{figure}

\section*{Data Storage Design}

\hspace\parindent
On initial start of the application, the user is met with the selection of add, open, and remove
folder. Every folder created is stored in the current working directory (\texttt{\$CWD}) of where 
the application was executed. This specifically appears on the \texttt{data/} folder which
can be located at \texttt{\$CWD/data/$<$folder\_name$>$}.
Inside \texttt{\$CWD/data/$<$folder\_name$>$}, is where the extracted text from an image will be
stored. The CSV file is also generated here replicating the name of its current folder 
(\texttt{$<$folder\_name$>$.csv}). This acts as a database of current selected image files to 
be run on by the Boyer-Moore Algorithm.

\begin{center}
\begin{tabular}{| c | c | c |}
    \hline
    \texttt{file\_key} & \texttt{file\_path} & \texttt{file\_name}\\
    \hline
    1 & \texttt{\textasciitilde/Projects/filename1.png} & filename1.png\\
    \hline
    2 & \texttt{\textasciitilde/Photos/filename2.jpeg} & filename2.jpeg\\
    \hline
    3 & \texttt{\textasciitilde/Downloads/images/filename3.jpg} & filename3.jpg\\
    \hline
    4 & \texttt{\textasciitilde/Projects/filename5.webp} & filename5.webp\\
    \hline
\end{tabular}
\end{center}

\section*{Image to Text Conversion}

\begin{figure}[hbt!]
    \center
    \noindent\adjustbox{width=.89\textwidth}{\includesvg{images/ocrapi}}
    \caption{Image to text extraction with Tesseract 4}
    \label{fig:ocrapi}
\end{figure}

SaLitrato is dependent on the stable version of Tesseract 4 for extracting text from image files. Tesseract 
is an OCR Engine focused on line and character recognition. With Python, the text extraction
API can be accessed via importing \texttt{image\_to\_string} on \texttt{pytesseract}
package.

\hfill

\noindent
\texttt{pytesseract} is a wrapper class that allows interaction with the Tesseract engine.


\section*{Data Structure Preparation for Indexing}

\begin{figure}[hbt!]
    \center
    \noindent\adjustbox{width=.95\textwidth}{\includesvg{images/data_format}}
    \caption{Structure of data for processing}
    \label{fig:data_structure1}
\end{figure}

In figure \ref{fig:data_structure1} shows how the data will be structured. This prepares the
text of each file to undergo what we call as indexing. Indexing refers to identification of the
location of a resource based on file names or key data fields in a record. Traversing through a
record like this (Fig \ref{fig:indexing}) would make tracking the index of where the current pattern appeared become easier.

\begin{figure}[hbt!]
   \center
   \noindent\includegraphics[width=\textwidth]{row_data.png}
   \caption{Sample data}
   \label{fig:indexing}
\end{figure}

\section*{Algorithm Design}

\hspace\parindent
Having multiple lists of text to traverse through requires a fast and efficient algorithm for
pattern matching. There are multiple string matching algorithms that exist like Naive Algorithm, Z
Algorithm, Knuth Morris Pratt, and Boyer-Moore algorithm.  Observing that
as the number of image files being included for search increases, the number of text for 
an algorithm to pass also increased drastically. Among said string matching algorithms,
\textbf{Boyer Moore string matching algorithm} works best in this kind of scenario. Though at worst
case it runs on $O(nm)$ where n is the length of text and m is the length of pattern, it is outweighed
by its best case of $O(n/m)$ assuming there are a limited number of matches that occured which happens to
be the case on having multiple texts to traverse.

\hfill

The \textbf{Boyer-Moore Algorithm} in this program uses bad character heuristics to determine where
the mismatch appeared. Multiple references exist for getting the code of this algorithm, which all
comes with several drawbacks. We take the example of what was written in GeeksForGeeks [21]. 

\hfill

\begin{tcolorbox}[colback=white, title=\textbf{Bad Character Preprocessing}]
    \begin{lstlisting}[style=py]
NO_OF_CHARS = 256
 
def badCharHeuristic(string, size):
    badChar = [-1]*NO_OF_CHARS
    for i in range(size):
        badChar[ord(string[i])] = i;
    # return bad_char_array

def search(txt, pat):
    badChar = badCharHeuristic(pat, m)
    # return indexes of where the patterns appeared
\end{lstlisting}
\end{tcolorbox}


\hfill

When this type of code is executed, multiple instances of \texttt{badChar} will be recreated for
every row there is to search for a match. This ramps up the complexity by increasing orders of
magnitude. The \texttt{badCharHeuristic()} function itself can get $O(size)$ as its complexity.
Without refactoring the code, it could reach a complexity of $O(size*rows)$ given the data is now
being traversed. It can be
prevented by decoupling \texttt{badCharHeuristic()} inside the \texttt{search()}. Making the search
contain \texttt{badChar} only as an argument.

\hfill

Another problem for the code shown above is the \texttt{NO\_OF\_CHARS = 256}. Giving a limit to
values that can be inserted into the bad character array, would most likely generate an \texttt{Out
of Bounds Exception} or
\texttt{IndexError}. The said error is raised when an index that is out of range or invalid for
a given data structure is being accessed. Making this array a hash table is one of the solution. Instead of being
allocated manually and limiting the extension of bad character array, it becomes dynamically allocated on its own.

\hfill

\begin{tcolorbox}[colback=white, title=\textbf{Modified Bad Character Preprocessing}]
\begin{lstlisting}[style=py]
def badCharHeuristic(pat):
    table = {}
    for i in range(len(pat)):
        table[pat[i]] = i
    return table
\end{lstlisting}

\hrulefill

\textbf{Sample input:} \texttt{and}

\textbf{Output:} \texttt{\{'a': 0, 'n': 1, 'd': 2\}}
\end{tcolorbox}

\section*{Retrieval of Matched Patterns}

\begin{figure}[hbt!]
    \center
    \noindent\adjustbox{}{\includesvg{images/result}}
    \caption{Generation of result}
    \label{fig:result}
\end{figure}

Getting the result of matches occured requires the algorithm to traverse on multiple list of
rows on each file while retrieving the current index of where each pattern started (Fig
\ref{fig:result}). It accesses the
data prepared for indexing which is stored in a dictionary or what we also call as hash table.
This hash table with key as file name and list of rows as value creates a versatile way of identifing
where we could find the result of the matching patterns.

\hfill

Results generated is then used for identifying what position should be highlighted on the Textbox.
Highlight for Textbox require the coordinates \texttt{begin=(row, column)} and \texttt{end=(row,
column + pattern.len)}.
